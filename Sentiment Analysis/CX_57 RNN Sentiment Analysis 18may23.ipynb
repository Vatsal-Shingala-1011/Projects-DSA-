{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35966e84",
   "metadata": {},
   "source": [
    "## Integer Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b611e068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "docs = ['Birds chirp cheerfully',\n",
    "        'Warm sun cool breeze',\n",
    "        'Flowers bloom brightly',\n",
    "        'Ocean waves crash',\n",
    "        'Coffee aroma fills',\n",
    "        'Birds Fly',\n",
    "        'sachin sachin',\n",
    "        'Books transport minds',\n",
    "        'good very good',\n",
    "        'coffee with warm coffee']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40b9882c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(oov_token='<nothing>') #oov= out of vocabulary tocken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d90a34c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d1c837d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<nothing>': 1,\n",
       " 'coffee': 2,\n",
       " 'birds': 3,\n",
       " 'warm': 4,\n",
       " 'sachin': 5,\n",
       " 'good': 6,\n",
       " 'chirp': 7,\n",
       " 'cheerfully': 8,\n",
       " 'sun': 9,\n",
       " 'cool': 10,\n",
       " 'breeze': 11,\n",
       " 'flowers': 12,\n",
       " 'bloom': 13,\n",
       " 'brightly': 14,\n",
       " 'ocean': 15,\n",
       " 'waves': 16,\n",
       " 'crash': 17,\n",
       " 'aroma': 18,\n",
       " 'fills': 19,\n",
       " 'fly': 20,\n",
       " 'books': 21,\n",
       " 'transport': 22,\n",
       " 'minds': 23,\n",
       " 'very': 24,\n",
       " 'with': 25}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a1b94a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('birds', 2),\n",
       "             ('chirp', 1),\n",
       "             ('cheerfully', 1),\n",
       "             ('warm', 2),\n",
       "             ('sun', 1),\n",
       "             ('cool', 1),\n",
       "             ('breeze', 1),\n",
       "             ('flowers', 1),\n",
       "             ('bloom', 1),\n",
       "             ('brightly', 1),\n",
       "             ('ocean', 1),\n",
       "             ('waves', 1),\n",
       "             ('crash', 1),\n",
       "             ('coffee', 3),\n",
       "             ('aroma', 1),\n",
       "             ('fills', 1),\n",
       "             ('fly', 1),\n",
       "             ('sachin', 2),\n",
       "             ('books', 1),\n",
       "             ('transport', 1),\n",
       "             ('minds', 1),\n",
       "             ('good', 2),\n",
       "             ('very', 1),\n",
       "             ('with', 1)])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f0685b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.document_count ## total lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c6da8ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 7, 8],\n",
       " [4, 9, 10, 11],\n",
       " [12, 13, 14],\n",
       " [15, 16, 17],\n",
       " [2, 18, 19],\n",
       " [3, 20],\n",
       " [5, 5],\n",
       " [21, 22, 23],\n",
       " [6, 24, 6],\n",
       " [2, 25, 4, 2]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = tokenizer.texts_to_sequences(docs)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5801a9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import pad_sequences ##appling pading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c42aa207",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = pad_sequences(sequences,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee99b6a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  7,  8,  0],\n",
       "       [ 4,  9, 10, 11],\n",
       "       [12, 13, 14,  0],\n",
       "       [15, 16, 17,  0],\n",
       "       [ 2, 18, 19,  0],\n",
       "       [ 3, 20,  0,  0],\n",
       "       [ 5,  5,  0,  0],\n",
       "       [21, 22, 23,  0],\n",
       "       [ 6, 24,  6,  0],\n",
       "       [ 2, 25,  4,  2]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29168ed",
   "metadata": {},
   "source": [
    "## Sentiment Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c578b31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense,SimpleRNN,Embedding,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9d9ea09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_train),(X_test,y_test) = imdb.load_data()\n",
    "# this imdb data set is already encoded in integer encoding so no need to encode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "06e1bd94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "05bacec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 22665,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 21631,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 19193,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 10311,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 31050,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 12118,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e2f8b2ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12ba9126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "05a37216",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train,padding='post',maxlen=50)\n",
    "X_test = pad_sequences(X_test,padding='post',maxlen=50)\n",
    "# X_train = pad_sequences(X_train,padding='post')\n",
    "# X_test = pad_sequences(X_test,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9ab99227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  132,     8,    67,     6,    22,    15,     9,   283,     8,\n",
       "        5168,    14,    31,     9,   242,   955,    48,    25,   279,\n",
       "       22148,    23,    12,  1685,   195,    25,   238,    60,   796,\n",
       "       13713,     4,   671,     7,  2804,     5,     4,   559,   154,\n",
       "         888,     7,   726,    50,    26,    49,  7008,    15,   566,\n",
       "          30,   579,    21,    64,  2574])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f48f3db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[3].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4954cfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add()\n",
    "# model.add(SimpleRNN(32,input_shape=(X_train[3].shape[0],1),return_sequences=False))# 50 is time step and 1 is input features\n",
    "# model.add(Dense(1,activation='sigmoid'))                                     ## in every time step give one word\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6f1cc25a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret initializer identifier: 50",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [50]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[1;32m----> 2\u001b[0m model\u001b[38;5;241m.\u001b[39madd(\u001b[43mEmbedding\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m) \u001b[38;5;66;03m#model.add(Embedding(voc_size, dim, input_length))\u001b[39;00m\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39madd(SimpleRNN(\u001b[38;5;241m32\u001b[39m,return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\u001b[38;5;66;03m# 50 is time step and 1 is input features\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m1\u001b[39m,activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m))                                     \u001b[38;5;66;03m## in every time step give one word\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\dtensor\\utils.py:96\u001b[0m, in \u001b[0;36mallow_initializer_layout.<locals>._wrap_function\u001b[1;34m(layer_instance, *args, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m layout:\n\u001b[0;32m     94\u001b[0m             layout_args[variable_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_layout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m layout\n\u001b[1;32m---> 96\u001b[0m init_method(layer_instance, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# Inject the layout parameter after the invocation of __init__()\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layout_param_name, layout \u001b[38;5;129;01min\u001b[39;00m layout_args\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\layers\\core\\embedding.py:159\u001b[0m, in \u001b[0;36mEmbedding.__init__\u001b[1;34m(self, input_dim, output_dim, embeddings_initializer, embeddings_regularizer, activity_regularizer, embeddings_constraint, mask_zero, input_length, sparse, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_dim \u001b[38;5;241m=\u001b[39m input_dim\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dim \u001b[38;5;241m=\u001b[39m output_dim\n\u001b[1;32m--> 159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings_initializer \u001b[38;5;241m=\u001b[39m \u001b[43minitializers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings_initializer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings_regularizer \u001b[38;5;241m=\u001b[39m regularizers\u001b[38;5;241m.\u001b[39mget(embeddings_regularizer)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivity_regularizer \u001b[38;5;241m=\u001b[39m regularizers\u001b[38;5;241m.\u001b[39mget(activity_regularizer)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\initializers\\__init__.py:213\u001b[0m, in \u001b[0;36mget\u001b[1;34m(identifier)\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m identifier\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 213\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    214\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not interpret initializer identifier: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(identifier)\n\u001b[0;32m    215\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Could not interpret initializer identifier: 50"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(10000,30,50)) #model.add(Embedding(voc_size, dim, input_length))\n",
    "model.add(SimpleRNN(32,return_sequences=False))# 50 is time step and 1 is input features\n",
    "model.add(Dense(1,activation='sigmoid'))                                     ## in every time step give one word\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1ab8c25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\vatsal shingala\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\vatsal shingala\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\vatsal shingala\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\vatsal shingala\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\vatsal shingala\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\vatsal shingala\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\vatsal shingala\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\vatsal shingala\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\vatsal shingala\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\losses.py\", line 2146, in binary_crossentropy\n        label_smoothing = tf.convert_to_tensor(label_smoothing, dtype=y_pred.dtype)\n\n    TypeError: Expected int32, but got 0.0 of type 'float'.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [49]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Users\\VATSAL~1\\AppData\\Local\\Temp\\__autograph_generated_file_dueldsd.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    File \"C:\\Users\\vatsal shingala\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\vatsal shingala\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\vatsal shingala\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\vatsal shingala\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\vatsal shingala\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\vatsal shingala\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\vatsal shingala\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\vatsal shingala\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\vatsal shingala\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\losses.py\", line 2146, in binary_crossentropy\n        label_smoothing = tf.convert_to_tensor(label_smoothing, dtype=y_pred.dtype)\n\n    TypeError: Expected int32, but got 0.0 of type 'float'.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train,y_train,epochs=20,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e2849a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d01d30b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
